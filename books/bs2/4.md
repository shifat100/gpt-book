# Chapter 4: Regression Analysis

## 4.1 Introduction to Regression Analysis

### What is Regression Analysis?

**Regression analysis** is a statistical technique used to model and analyze the relationship between a dependent variable and one or more independent variables. Unlike correlation, which merely measures the strength of association, regression allows us to **predict** and **estimate** values.

**Historical Note:** The term "regression" was coined by Sir Francis Galton (1886) while studying heredity. He observed that extreme characteristics in parents tended to "regress" toward average values in their children.

**Business Definition:** Regression analysis helps us:
- Predict future outcomes based on historical data
- Quantify the impact of independent variables on dependent variables
- Make informed business decisions with numerical precision
- Estimate values for planning and forecasting

### Key Applications in Business

**1. Sales Forecasting:**
- Predict sales based on advertising expenditure
- Estimate revenue from marketing investments

**2. Financial Planning:**
- Project future costs based on production levels
- Estimate budget requirements

**3. Human Resources:**
- Predict employee performance from training hours
- Estimate salary requirements based on experience

**4. Operations Management:**
- Forecast demand based on historical patterns
- Estimate production costs from volume

**5. Marketing:**
- Predict customer lifetime value
- Estimate market share from competitive factors

---

## 4.2 Regression vs. Correlation: Understanding the Difference

While correlation and regression are related concepts, they serve different purposes and have important distinctions.

### Correlation Analysis

**Purpose:** Measures the strength and direction of association between two variables

**Key Characteristics:**
- **Symmetric:** Correlation between X and Y equals correlation between Y and X
- **No causation implied:** Simply measures association
- **Dimensionless:** No units, always between -1 and +1
- **No prediction:** Only describes relationship strength
- **Equal treatment:** Neither variable is designated as dependent or independent

**Example:** r = 0.85 between advertising and sales tells us they're strongly related, but doesn't help predict specific sales values.

### Regression Analysis

**Purpose:** Models the relationship to predict or estimate one variable from another

**Key Characteristics:**
- **Asymmetric:** Regression of Y on X differs from regression of X on Y
- **Implies direction:** One variable (Y) depends on another (X)
- **Has units:** Equation has units of dependent variable
- **Enables prediction:** Provides equation to estimate Y from X
- **Unequal roles:** Clear distinction between dependent (Y) and independent (X) variables

**Example:** Sales = 10,000 + 2,500(Advertising) allows us to predict that $5,000 in advertising will yield $22,500 in sales.

### Comparison Table

| **Aspect** | **Correlation** | **Regression** |
|------------|----------------|----------------|
| **Question Asked** | "How strong is the relationship?" | "What is the relationship equation?" |
| **Output** | Single number (r) | Equation (Y = a + bX) |
| **Purpose** | Measure association | Prediction and estimation |
| **Symmetry** | Symmetric | Asymmetric |
| **Variables** | Both treated equally | Y (dependent), X (independent) |
| **Units** | Unitless | Has units of Y |
| **Causation** | Never implies | Suggests direction (but doesn't prove) |
| **Use Case** | "Are these related?" | "What will Y be if X changes?" |

### Relationship Between Correlation and Regression

While different, correlation and regression are mathematically related:

$$r = b \times \frac{s_X}{s_Y}$$

**Where:**
- r = Correlation coefficient
- b = Regression slope coefficient
- s_X = Standard deviation of X
- s_Y = Standard deviation of Y

**Important Points:**
1. Both measure linear relationships
2. High correlation (r near ±1) suggests regression will predict well
3. Low correlation (r near 0) suggests regression predictions will be poor
4. Regression provides the "best-fitting" line through data points

### When to Use Each

**Use Correlation When:**
- You want to know if two variables are related
- Direction of relationship is unclear
- No prediction is needed
- Both variables measured with similar importance
- Example: "Is employee satisfaction related to productivity?"

**Use Regression When:**
- You want to predict one variable from another
- Clear dependent and independent variables exist
- Quantitative predictions are needed
- Understanding impact magnitude is important
- Example: "How much will sales increase if we spend $10,000 more on advertising?"

**Use Both:**
In practice, start with correlation to assess relationship strength, then use regression for prediction if correlation is significant.

---

## 4.3 Types of Regression Lines

In bivariate analysis (two variables), there are actually **two different regression lines** depending on which variable we're trying to predict.

### Line of Regression of Y on X

**Purpose:** Predict Y from given values of X

**Notation:** Y on X, or Ŷ (Y-hat)

**Equation:**
$$Y = a + bX$$

**When to Use:**
- Y is the dependent (response) variable
- X is the independent (predictor) variable
- We want to estimate Y for given values of X

**Business Example:** Predicting sales (Y) from advertising expenditure (X)

**Visual Representation:**
```
Sales (Y)
    |         ● 
    |       ●   
    |     ●  /
    |   ●  /  ← Line Y on X
    | ●  /
    |  /
    |/_________________
           Advertising (X)

Minimizes vertical distances from points to line
```

### Line of Regression of X on Y

**Purpose:** Predict X from given values of Y

**Notation:** X on Y

**Equation:**
$$X = a' + b'Y$$

**When to Use:**
- X is the dependent variable (to be predicted)
- Y is the independent variable (known)
- We want to estimate X for given values of Y

**Business Example:** Estimating required advertising budget (X) to achieve target sales (Y)

**Visual Representation:**
```
Sales (Y)
    |         ● 
    |       ●   
    |     ●  
    |   ●  ___
    | ●___/  ← Line X on Y
    | /
    |/_________________
           Advertising (X)

Minimizes horizontal distances from points to line
```

### Key Differences Between the Two Lines

**1. Direction of Prediction:**
- **Y on X:** Predict Y when X is known
- **X on Y:** Predict X when Y is known

**2. Minimization Criterion:**
- **Y on X:** Minimizes sum of squared vertical deviations
- **X on Y:** Minimizes sum of squared horizontal deviations

**3. Slopes:**
- Generally different slopes: b ≠ 1/b'
- Only identical when r = ±1 (perfect correlation)

**4. Intercepts:**
- Different y-intercepts
- Different x-intercepts

### Relationship Between the Two Lines

**Important Properties:**

**1. Point of Intersection:**
Both lines always pass through the point $(\bar{X}, \bar{Y})$ - the means of X and Y.

**2. Mathematical Relationship:**
$$b \times b' = r^2$$

Where:
- b = slope of Y on X
- b' = slope of X on Y  
- r = correlation coefficient

**3. Angle Between Lines:**
- When r = ±1: Lines coincide (perfect correlation)
- When r = 0: Lines are perpendicular (no correlation)
- When 0 < |r| < 1: Lines intersect at $(\bar{X}, \bar{Y})$ at an angle

**Visual: Relationship Between Lines and Correlation**

```
Perfect Correlation (r = ±1):
Y |     ●
  |   ●    Both lines
  | ●      coincide
  |_________ X

No Correlation (r = 0):
Y |  ●   ●
  |    |     Lines
  |____|___  perpendicular
  |    ●  ● 
  |_________ X

Moderate Correlation (0 < r < 1):
Y |     ●      Y on X /
  |   ●      /
  | ●      /   X on Y __
  |______/___________
        (\bar{X}, \bar{Y})
```

### Which Line Should You Use?

**Decision Criteria:**

**Use Y on X when:**
- Purpose is to predict Y
- X is controlled or predetermined
- X is measured without error (or with less error)
- Most common in business applications

**Use X on Y when:**
- Purpose is to predict X
- Y is the controlled variable
- Need to work backwards from outcomes
- Less common but still important

**Business Example:**
- **Y on X:** "If we spend $15,000 on advertising, what sales can we expect?"
- **X on Y:** "To achieve $100,000 in sales, how much should we budget for advertising?"

### Common Mistake

**Error:** Using the same equation for both directions

**Wrong:** Using Y = a + bX, then rearranging to X = (Y - a)/b

**Correct:** Calculate separate equations for Y on X and X on Y

**Why it matters:** The two approaches give different predictions because they minimize different error measures.

---

## 4.4 The Least Squares Method

### Concept of Least Squares

The **Least Squares Method** is a mathematical procedure for finding the "best-fitting" straight line through a set of data points. "Best-fitting" means the line that minimizes the sum of squared vertical distances between observed Y values and predicted Y values.

**Developed by:** Carl Friedrich Gauss (1795) and Adrien-Marie Legendre (1805)

### Why "Least Squares"?

**The Problem:** Given data points, infinite lines can be drawn. Which one is "best"?

**The Solution:** Choose the line that minimizes prediction errors.

**Mathematical Criterion:**
$$\text{Minimize: } \sum_{i=1}^{n}(Y_i - \hat{Y}_i)^2$$

**Where:**
- $Y_i$ = Actual (observed) value
- $\hat{Y}_i$ = Predicted value from regression line
- $(Y_i - \hat{Y}_i)$ = Error (residual)
- Square ensures positive values and penalizes large errors more

**Visual Representation:**
```
Y |        ●  ← Actual point
  |        |
  |        | ← Vertical distance (error)
  |        |
  |        ●______ ← Point on regression line
  |       /
  |     /
  |   / ← Regression line
  | /
  |/_________________ X

Least squares minimizes the sum of all squared vertical distances
```

### The Simple Linear Regression Equation

**General Form:**
$$Y = a + bX$$

**Or:**
$$\hat{Y} = a + bX$$

**Where:**
- $\hat{Y}$ (Y-hat) = Predicted value of Y
- Y = Dependent variable (response)
- X = Independent variable (predictor)
- a = Y-intercept (constant term)
- b = Slope (regression coefficient)

### Components of the Equation

#### **1. Slope (b) - Regression Coefficient**

**Definition:** The rate of change in Y for a one-unit change in X.

**Formula:**
$$b = \frac{n\sum XY - \sum X \sum Y}{n\sum X^2 - (\sum X)^2}$$

**Alternative Formula (using correlation):**
$$b = r \times \frac{s_Y}{s_X}$$

**Interpretation:**
- **Positive b:** Y increases as X increases
- **Negative b:** Y decreases as X increases
- **Magnitude:** Size indicates strength of effect

**Example:** b = 2,500 means "each additional $1,000 in advertising increases sales by $2,500"

#### **2. Y-Intercept (a) - Constant Term**

**Definition:** The value of Y when X = 0.

**Formula:**
$$a = \bar{Y} - b\bar{X}$$

**Where:**
- $\bar{Y}$ = Mean of Y values
- $\bar{X}$ = Mean of X values

**Interpretation:**
- Theoretical value of Y when X is zero
- Often has no practical meaning (especially if X = 0 is outside data range)
- Necessary for mathematical completeness of equation

**Example:** a = 10,000 means "when advertising = $0, base sales = $10,000"

### Derivation Logic (Conceptual)

**Step 1:** Start with the general equation: $\hat{Y} = a + bX$

**Step 2:** For each data point, calculate error: $e_i = Y_i - \hat{Y}_i$

**Step 3:** Define total error: $SSE = \sum e_i^2 = \sum(Y_i - a - bX_i)^2$

**Step 4:** Find values of a and b that minimize SSE using calculus:
- Take partial derivative with respect to a and set to 0
- Take partial derivative with respect to b and set to 0
- Solve the resulting "normal equations"

**Result:** The formulas for a and b given above.

### Properties of the Regression Line

**1. Always passes through $(\bar{X}, \bar{Y})$**
- The line goes through the point of means
- Guarantees centrality of fit

**2. Sum of residuals = 0**
$$\sum(Y_i - \hat{Y}_i) = 0$$
- Positive and negative errors cancel out
- No systematic over or under-prediction

**3. Minimizes SSE**
- No other line has smaller sum of squared errors
- Optimal in least squares sense

**4. Uncorrelated residuals and X**
- Errors have no pattern with X
- Validates linear model assumption

---

## 4.5 Worked Example: Complete Regression Analysis

### **Business Scenario: Advertising and Sales Relationship**

Let's use the same data from Chapter 3 (Advertising Spend vs. Sales Revenue) to develop a regression model that **BrightTech Solutions** can use to predict sales from advertising expenditure.

**Recall the data:**

| **Month** | **Advertising Spend (X)** | **Sales Revenue (Y)** |
|-----------|--------------------------|----------------------|
|           | (in $1,000s) | (in $10,000s) |
| 1 | 2 | 15 |
| 2 | 3 | 18 |
| 3 | 5 | 25 |
| 4 | 4 | 22 |
| 5 | 7 | 30 |
| 6 | 6 | 28 |
| 7 | 8 | 35 |
| 8 | 5 | 24 |

**Management Questions:**
1. What is the regression equation?
2. What do the coefficients mean in business terms?
3. If we spend $9,000 on advertising, what sales can we expect?
4. How reliable is this prediction?

---

### **Solution:**

#### **Step 1: Recall Previous Calculations**

From Chapter 3, we already calculated:
- n = 8
- ΣX = 40
- ΣY = 197
- ΣX² = 228
- ΣY² = 5,143
- ΣXY = 1,075
- r = 0.996

We also need the means:
$$\bar{X} = \frac{\sum X}{n} = \frac{40}{8} = 5$$

$$\bar{Y} = \frac{\sum Y}{n} = \frac{197}{8} = 24.625$$

---

#### **Step 2: Calculate the Slope (b)**

**Formula:**
$$b = \frac{n\sum XY - \sum X \sum Y}{n\sum X^2 - (\sum X)^2}$$

**Calculation:**

**Numerator:**
$$n\sum XY - \sum X \sum Y = 8(1,075) - (40)(197)$$
$$= 8,600 - 7,880 = 720$$

**Denominator:**
$$n\sum X^2 - (\sum X)^2 = 8(228) - (40)^2$$
$$= 1,824 - 1,600 = 224$$

**Slope:**
$$b = \frac{720}{224} = 3.214$$

**Rounded: b = 3.21**

---

#### **Step 3: Calculate the Y-Intercept (a)**

**Formula:**
$$a = \bar{Y} - b\bar{X}$$

**Calculation:**
$$a = 24.625 - 3.214(5)$$
$$a = 24.625 - 16.070$$
$$a = 8.555$$

**Rounded: a = 8.56**

---

#### **Step 4: Write the Regression Equation**

**Equation:**
$$\hat{Y} = 8.56 + 3.21X$$

**Or in business terms:**
$$\text{Predicted Sales} = 8.56 + 3.21 \times (\text{Advertising Spend})$$

**Where:**
- Sales is measured in $10,000s
- Advertising Spend is measured in $1,000s

---

#### **Step 5: Interpret the Coefficients**

**Slope (b = 3.21):**

**Statistical Interpretation:**
- For every one-unit increase in X, Y increases by 3.21 units
- For every additional $1,000 spent on advertising, sales increase by 3.21 units ($32,100)

**Business Interpretation:**
- **Return on Advertising:** Each $1,000 invested in advertising generates approximately $32,100 in additional sales
- **ROI:** This represents a 3,110% return on advertising investment
- **Strategic Implication:** Advertising is highly effective for this company
- **Positive Relationship:** More advertising consistently leads to higher sales

**Y-Intercept (a = 8.56):**

**Statistical Interpretation:**
- When X = 0, Y = 8.56

**Business Interpretation:**
- **Base Sales:** When advertising expenditure is zero, expected sales are 8.56 units ($85,600)
- **Interpretation:** This represents baseline sales from:
  - Existing brand recognition
  - Word-of-mouth referrals
  - Organic website traffic
  - Repeat customers
  - Walk-in traffic
- **Caution:** X = 0 is at the edge of our data range (minimum X = 2), so this extrapolation should be treated cautiously

---

#### **Step 6: Make Predictions**

**Question:** If BrightTech spends $9,000 on advertising next month, what sales can they expect?

**Given:** X = 9 (representing $9,000)

**Prediction:**
$$\hat{Y} = 8.56 + 3.21(9)$$
$$\hat{Y} = 8.56 + 28.89$$
$$\hat{Y} = 37.45$$

**Answer:** Expected sales = 37.45 units = **$374,500**

**Confidence in Prediction:**
- r² = (0.996)² = 0.992 = 99.2%
- Very high explanatory power
- Prediction is highly reliable within the data range
- Note: X = 9 is slightly outside observed range (2-8), so use caution

---

#### **Step 7: Verify the Regression Line**

Let's verify that our line passes through $(\bar{X}, \bar{Y})$:

$$\hat{Y} = 8.56 + 3.21(5) = 8.56 + 16.05 = 24.61$$

This equals $\bar{Y} = 24.625$ ✓ (small difference due to rounding)

---

#### **Step 8: Create Prediction Table**

**Practical Applications:**

| **Advertising Budget** | **Predicted Sales** | **Calculation** |
|----------------------|-------------------|----------------|
| $3,000 | $17.19 × 10,000 = $171,900 | 8.56 + 3.21(3) |
| $5,000 | $24.61 × 10,000 = $246,100 | 8.56 + 3.21(5) |
| $7,000 | $31.03 × 10,000 = $310,300 | 8.56 + 3.21(7) |
| $10,000 | $40.66 × 10,000 = $406,600 | 8.56 + 3.21(10) |

---

#### **Step 9: Visual Representation**

```
Sales
($10K)
  |
40|                          ● (Predicted for X=9)
  |                      ●
35|                  ●  /
  |              ●  /  
30|          ●  /  
  |      ●  / ← Regression Line
25|    ●  /    Ŷ = 8.56 + 3.21X
  |   /  ●
20|  /
  | /  ●
15| /
  |/
10|← Y-intercept = 8.56
  |_________________________________
   0  1  2  3  4  5  6  7  8  9  10
              Advertising ($1000s)
```

---

#### **Step 10: Comprehensive Business Interpretation**

**Key Findings:**

**1. Strong Predictive Power:**
- r² = 99.2% means the model explains nearly all variation in sales
- Very reliable for forecasting and planning
- Minimal unexplained variance

**2. Advertising Effectiveness:**
- **ROI:** $32.10 in sales per $1 advertising (3,110% return)
- Advertising is the dominant driver of sales for this company
- Strong justification for continued advertising investment

**3. Strategic Implications:**

**A. Budget Planning:**
- Can confidently set advertising budgets to meet sales targets
- Example: To achieve $300,000 in sales, invest: X = (30 - 8.56)/3.21 = 6.67, or $6,670

**B. Scalability:**
- Model suggests linear relationship holds across observed range
- Can scale advertising up or down predictably
- Should test if relationship holds beyond $8,000 (potential diminishing returns)

**C. Minimum Investment:**
- Even with zero advertising, base sales of $85,600 expected
- Represents strength of brand and existing customer base
- Provides safety cushion in low-advertising scenarios

**4. Cautions and Limitations:**

**A. Extrapolation Risk:**
- Model based on data from $2,000-$8,000 range
- Predictions beyond this range (especially $9,000+) less reliable
- May encounter diminishing returns or market saturation at higher levels

**B. Other Factors:**
- Model doesn't account for:
  - Seasonal variations
  - Economic conditions
  - Competitor actions
  - Product quality changes
  - Market trends
- These factors explain remaining 0.8% of variance

**C. Causation:**
- While correlation is very strong, controlled experiments would strengthen causal claims
- Consider A/B testing to confirm advertising directly causes sales increases

**5. Recommendations:**

**Immediate Actions:**
- Use equation for monthly sales forecasting
- Set advertising budgets based on desired sales targets
- Monitor actual vs. predicted sales to validate model

**Further Analysis:**
- Extend data collection to 12-24 months
- Test higher advertising levels to detect saturation point
- Incorporate seasonal factors if pattern emerges
- Calculate prediction intervals for risk management
- Develop contingency plans for when predictions deviate

**Long-term Strategy:**
- Quarterly review of regression coefficients
- Investigate diminishing returns threshold
- Explore additional predictor variables (price, economy, competition)
- Consider multiple regression for more comprehensive model

---

## 4.6 Properties of Regression Coefficients

Understanding the properties of regression coefficients helps in proper interpretation and application of regression analysis.

### Property 1: Relationship with Correlation

The regression coefficient (b) is related to the correlation coefficient (r):

$$b = r \times \frac{s_Y}{s_X}$$

**Implications:**
- When variables have same standard deviation: b = r
- b has same sign as r (both positive or both negative)
- If r = 0, then b = 0 (no relationship)
- Strong correlation doesn't guarantee large b (depends on scale)

### Property 2: Units and Scale

**Slope (b):**
- Has units: (units of Y) / (units of X)
- Scale-dependent: Changes if units change
- Example: b = 3.21 means "$10,000 in sales per $1,000 advertising"

**Intercept (a):**
- Has same units as Y
- Represents Y-value when X = 0
- May lack practical meaning if X = 0 is impossible or outside data range

**Important:** Changing units changes coefficients but not the underlying relationship!

**Example:**
- Original: Y (in $10,000s) = 8.56 + 3.21X (in $1,000s)
- Converted: Y (in $) = 85,600 + 3.21X (in $)

### Property 3: Sign and Direction

**Positive b (b > 0):**
- Positive relationship
- Y increases as X increases
- Upward-sloping line
- Example: Price and perceived quality

**Negative b (b < 0):**
- Negative (inverse) relationship
- Y decreases as X increases
- Downward-sloping line
- Example: Price and quantity demanded

**Zero b (b = 0):**
- No linear relationship
- Horizontal regression line
- Y doesn't change with X
- Example: Sales and employee shoe size

### Property 4: Magnitude and Interpretation

**Small |b|:**
- Weak effect of X on Y
- Flat regression line
- X doesn't strongly influence Y

**Large |b|:**
- Strong effect of X on Y
- Steep regression line
- X has substantial impact on Y

**Caution:** "Large" vs. "small" depends on context and units!

### Property 5: Relationship Between Two Regression Lines

For regression of Y on X and X on Y:

$$b_{Y \text{ on } X} \times b_{X \text{ on } Y} = r^2$$

**Implications:**
- Product of slopes equals squared correlation
- If r = ±1: b × (1/b) = 1 (lines coincide)
- If r = 0: At least one slope = 0 (perpendicular lines)

### Property 6: Invariance of Residuals

**Sum of residuals = 0:**
$$\sum(Y_i - \hat{Y}_i) = 0$$

**Meaning:**
- Positive and negative errors cancel
- No systematic bias
- Regression line balances errors

**Sum of squared residuals is minimized:**
$$SSE = \sum(Y_i - \hat{Y}_i)^2 \text{ is minimum}$$

**Meaning:**
- No other line fits better (in least squares sense)
- Optimal prediction given linear model

### Property 7: Sensitivity to Outliers

**Regression coefficients are sensitive to extreme values:**
- Single outlier can dramatically change slope
- More sensitive than correlation coefficient
- Always check for and investigate outliers

**Example:**
```
Before Removing Outlier:        After Removing Outlier:
Y |              ●(outlier)      Y |           
  |         /                      |      ●  ●  /
  |    ●  /                        |    ●  ●  /
  |  ●  / ← steep slope            |  ●  ●  / ← moderate slope
  |____________________            |____________________
        X                                  X
```

### Property 8: No Guarantee of Causation

**Important:** Large, significant regression coefficient does NOT prove causation!

**b can be large due to:**
- X causes Y (true causal effect)
- Y causes X (reverse causation)
- Z causes both X and Y (confounding)
- Spurious correlation
- Random chance (with small samples)

**Establishing causation requires:**
- Theoretical justification
- Temporal precedence
- Controlled experiments
- Ruling out confounders

### Property 9: Standardized Regression Coefficient

**Unstandardized b:** Original scale (as calculated)

**Standardized β (beta):**
$$\beta = b \times \frac{s_X}{s_Y} = r$$

**For simple regression:** β = r

**Advantage:** 
- Unit-free
- Allows comparison across different scales
- Interpreted as "standard deviations of Y change per standard deviation change in X"

### Property 10: Confidence Intervals

Regression coefficients have uncertainty (sampling variability):

**Confidence Interval for b:**
$$b \pm t_{\alpha/2, n-2} \times SE_b$$

**Where:**
- $t_{\alpha/2, n-2}$ = Critical t-value
- $SE_b$ = Standard error of slope
- Provides range of plausible values for true population slope

**Interpretation:**
- Narrow CI: Precise estimate
- Wide CI: Uncertain estimate
- If CI includes 0: Relationship may not be significant

---

## Summary of Chapter 4

**1. Regression analysis** provides equations for prediction and estimation, going beyond correlation's measure of association.

**2. Key differences:**
- **Correlation:** Measures strength of relationship
- **Regression:** Provides prediction equation

**3. Two regression lines:**
- **Y on X:** Predicts Y from X (most common)
- **X on Y:** Predicts X from Y

**4. Least squares method:**
- Minimizes sum of squared vertical deviations
- Provides "best-fitting" line mathematically

**5. Regression equation: Y = a + bX**
- **Slope (b):** Rate of change in Y per unit change in X
- **Intercept (a):** Value of Y when X = 0

**6. Interpretation is key:**
- Always express coefficients in business context
- Consider units and scale
- Don't confuse correlation with causation

**7. Regression coefficients:**
- Have specific mathematical properties
- Sensitive to outliers
- Related to correlation coefficient
- Enable quantitative predictions

---

## Practice Questions

**1. Conceptual:**
Explain why regression analysis is more useful than correlation analysis for business forecasting. Provide a specific example.

**2. Calculation:**
Given the following data on employee training hours (X) and productivity score (Y):

| Training Hours (X) | 10 | 15 | 20 | 25 | 30 |
| Productivity (Y) | 65 | 70 | 75 | 82 | 88 |

Calculate:
a) The regression equation Y = a + bX
b) Interpret the slope in business terms
c) Predict productivity for 22 hours of training

**3. Interpretation:**
A regression analysis shows: Profit = -50,000 + 25X, where X = number of units sold.
a) Interpret the slope coefficient
b) Interpret the intercept (explain why it's negative)
c) How many units must be sold to break even?

**4. Application:**
A company's regression analysis shows: Sales = 100 + 2.5(Advertising) with r² = 0.85.
a) If advertising increases by $10,000, what is the expected change in sales?
b) What does r² = 0.85 mean in business terms?
c) Would you recommend using this model? Why or why not?

**5. Critical Thinking:**
A regression shows that ice cream sales increase by $5,000 for every 1°F increase in temperature. Does this mean temperature causes ice cream sales? What other factors should be considered?
